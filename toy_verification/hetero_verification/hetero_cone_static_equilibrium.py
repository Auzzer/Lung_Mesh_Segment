"""
Cone Static Equilibrium Solver for Homogenization Verification

MODIFIED FROM: Static_Equilibrium_Simplified_V2_scipy_version.py
PURPOSE: Cone-specific verification case for SMS homogenization validation

This file solves static equilibrium on the preprocessed cone data using the SMS
(Second Moment of Stiffness) approach. It enables comparison between standard FEM 
linear elasticity and the SMS approach to validate the homogenization methodology.

WORKFLOW:
1. Load preprocessed data from cone_verification_deformation.npz
   - Contains mesh, material properties, deformation analysis, SMS measurement rows
   - Generated by hetero_cone_deformation_processor.py
2. Apply boundary conditions (clamp top face)
3. Solve static equilibrium using SMS approach
4. Compare SMS solution with FEM reference solution
5. Save results to xdmf_visualization/ folder

KEY MODIFICATIONS FROM ORIGINAL:
- Adapted for cone geometry
- Simplified boundary conditions (clamp top face)
- Saves mesh files (XDMF) for visualization
- Uses exact heterogeneous material properties from FEM
- Added quantitative FEM comparison
"""

import taichi as ti
import numpy as np
import torch
from pathlib import Path
import meshio

ti.init(arch=ti.cuda, device_memory_fraction=0.9, debug=False, kernel_profiler=False)

@ti.data_oriented
class ConeStaticEquilibrium:
    def __init__(self, preprocessed_data_path):
        """Initialize solver with preprocessed cone data"""
        # Load preprocessed data
        data = np.load(preprocessed_data_path, allow_pickle=True)
        
        self.N = data['mesh_points'].shape[0]  # #nodes
        self.M = data['tetrahedra'].shape[0]   # #tets

        # Core Taichi data fields
        self.x = ti.Vector.field(3, ti.f32, shape=self.N)      # current positions
        self.tets = ti.Vector.field(4, ti.i32, shape=self.M)   # tetrahedron indices
        self.vol = ti.field(ti.f32, shape=self.M)              # volumes
        self.mass = ti.field(ti.f32, shape=self.N)             
        
        # Spring System Fields
        self.intersection_points = ti.Vector.field(3, ti.f32, shape=(self.M, 6))
        self.intersection_valid = ti.field(ti.i32, shape=(self.M, 6))
        self.intersection_face = ti.field(ti.i32, shape=(self.M, 6))
        self.C_k = ti.field(ti.f32, shape=(self.M, 4, 6))
        
        self.alpha_k = ti.field(ti.f32, shape=self.M)
        self.beta_k = ti.field(ti.f32, shape=self.M)
        self.kappa_k = ti.field(ti.f32, shape=self.M)
        
        # Boundary conditions
        self.boundary_nodes = ti.field(ti.i32, shape=self.N)
        self.boundary_displacement = ti.Vector.field(3, ti.f32, shape=self.N)
        self.is_boundary_constrained = ti.field(ti.i32, shape=self.N)
        
        # SMS measurement rows from preprocessing
        self.r_axis  = ti.Vector.field(12, ti.f32, shape=(self.M, 3))
        self.r_shear = ti.Vector.field(12, ti.f32, shape=(self.M, 3))
        self.r_vol   = ti.Vector.field(12, ti.f32, shape=self.M)
        
        # Static equilibrium solver fields
        self.residual = ti.Vector.field(3, ti.f32, shape=self.N)
        self.solution_increment = ti.Vector.field(3, ti.f32, shape=self.N)
        self.temp_b = ti.field(ti.f32, shape=3*self.N)
        self.temp_x = ti.field(ti.f32, shape=3*self.N)
        self._cur_k = ti.field(dtype=ti.i32, shape=())
        self._nnz_counter = ti.field(dtype=ti.i32, shape=())
        
        self.initial_positions = ti.Vector.field(3, ti.f32, shape=self.N)
        self.displacement_field = ti.Vector.field(3, ti.f32, shape=self.N)
        
        # Store mesh connectivity for output
        self.mesh_connectivity = None
        self.nu_value = None
        self.labels_np = None

        # Load preprocessed data and initialize
        self._load_preprocessed_data(data)
        self._initialize_solver_fields()

    def _load_preprocessed_data(self, data):
        """Load all preprocessed data from cone deformation processor"""
        # Basic mesh data
        mesh_points = data['mesh_points'].astype(np.float64)
        tetrahedra = data['tetrahedra'].astype(np.int32)
        volume = data['volume'].astype(np.float64)
        mass = data['mass'].astype(np.float64)
        labels = data['labels'].astype(np.int32)

        alpha_np = data['alpha_k'].astype(np.float64)
        beta_np = data['beta_k'].astype(np.float64)
        kappa_np = data['kappa_k'].astype(np.float64)

        self.x.from_numpy(mesh_points)
        self.tets.from_numpy(tetrahedra)
        self.vol.from_numpy(volume)
        self.mass.from_numpy(mass)
        self.labels_np = labels

        if 'nu' in getattr(data, 'files', []):
            self.nu_value = float(data['nu'])
        else:
            self.nu_value, has_variation = self._infer_poisson_from_parameters(
                beta_np, kappa_np
            )
            if self.nu_value is None:
                print(
                    "Warning: Unable to infer Poisson ratio from preprocessed data"
                )
            elif has_variation:
                print(
                    "Warning: Poisson ratio varies across elements; "
                    f"using average nu={self.nu_value:.6f}"
                )
            else:
                print(
                    "Inferred Poisson ratio "
                    f"nu={self.nu_value:.6f} from Lamé parameters"
                )

        # Spring system data
        self.intersection_points.from_numpy(
            data['intersection_points'].astype(np.float64)
        )
        self.intersection_valid.from_numpy(
            data['intersection_valid'].astype(np.int32)
        )
        self.C_k.from_numpy(data['coefficient_matrix'].astype(np.float64))
        
        # SMS measurement rows
        self.r_axis.from_numpy(data['r_axis'].astype(np.float64))
        self.r_shear.from_numpy(data['r_shear'].astype(np.float64))
        self.r_vol.from_numpy(data['r_vol'].astype(np.float64))

        self.alpha_k.from_numpy(alpha_np)
        self.beta_k.from_numpy(beta_np)
        self.kappa_k.from_numpy(kappa_np)

        # Boundary conditions
        self.boundary_nodes.from_numpy(data['boundary_nodes'].astype(np.int32))
        self.initial_positions.from_numpy(data['initial_positions'].astype(np.float64))
        self.displacement_field.from_numpy(data['displacement_field'].astype(np.float64))
        
        # Store mesh connectivity for mesh file output
        self.mesh_connectivity = tetrahedra
        
        print(f"Loaded cone preprocessed data: {self.N} nodes, {self.M} tetrahedra")
        print(f"Boundary nodes: {np.sum(data['boundary_nodes'])}")
        print(
            "Valid intersections: "
            f"{np.sum(data['intersection_valid'])}/{data['intersection_valid'].size}"
        )

    def _infer_poisson_from_parameters(self, beta_np, kappa_np):
        """Infer a representative Poisson ratio from Lamé parameters."""
        with np.errstate(divide='ignore', invalid='ignore'):
            denom = 2.0 * (kappa_np + beta_np)
            nu_elements = np.where(denom != 0.0, kappa_np / denom, np.nan)
        finite = nu_elements[np.isfinite(nu_elements)]
        if finite.size == 0:
            return None, False
        nu_candidate = float(np.nanmean(finite))
        deviation = float(np.nanmax(np.abs(finite - nu_candidate))) if finite.size else 0.0
        has_variation = deviation > 1e-6
        return nu_candidate, has_variation

    @ti.kernel
    def _initialize_solver_fields(self):
        """Initialize solver-specific fields"""
        for i in range(self.N):
            self.residual[i] = ti.Vector([0.0, 0.0, 0.0])
            self.solution_increment[i] = ti.Vector([0.0, 0.0, 0.0])
            self.boundary_displacement[i] = ti.Vector([0.0, 0.0, 0.0])
            self.is_boundary_constrained[i] = 0
        
        for i in range(3 * self.N):
            self.temp_b[i] = 0.0
            self.temp_x[i] = 0.0

    def apply_cone_boundary_conditions(self):
        """Apply boundary conditions specific to cone geometry - constrain top face"""
        # BC application for cone (clamp top face)
        self._apply_cone_constraints()
        constrained_count = self._count_constrained_nodes()
        print(f"Applied cone boundary conditions to {constrained_count} nodes (top face)")
        self._build_dof_map()

    @ti.kernel
    def _apply_cone_constraints(self):
        """Apply constraints to cone top face - set displacement to zero (clamped)"""
        for i in range(self.N):
            if self.boundary_nodes[i] == 1:  # This is a boundary node (top face)
                # For cone verification, we clamp the top face (zero displacement)
                self.boundary_displacement[i] = ti.Vector([0.0, 0.0, 0.0])
                self.is_boundary_constrained[i] = 1
                # Keep position at initial value (no displacement)
                self.x[i] = self.initial_positions[i]

    def _count_constrained_nodes(self):
        """Count number of nodes with Dirichlet constraints applied"""
        return int(self.is_boundary_constrained.to_numpy().sum())

    def _build_dof_map(self):
        """Build mapping from global DOFs to free DOFs"""
        dof_map_np = -np.ones(3*self.N, dtype=np.int32)
        cnt = 0
        is_bc = self.is_boundary_constrained.to_numpy()
        for i in range(self.N):
            if is_bc[i] == 0:  # Free node
                for d in range(3):
                    dof_map_np[3*i + d] = cnt
                    cnt += 1
        self.n_free_dof = int(cnt)
        self.dof_map = ti.field(ti.i32, shape=3*self.N)
        self.dof_map.from_numpy(dof_map_np)


    def _alloc_free_buffers(self):
        """Allocate buffers for free DOF system"""
        n = int(self.n_free_dof)
        self.b_free = ti.field(ti.f32, shape=n)
        self.x_free = ti.field(ti.f32, shape=n)

    @ti.kernel
    def _build_rhs_free(self, b: ti.template()):
        """Assemble external loads (gravity) on free DOFs only"""
        g = ti.Vector([0.0, 0.0, -9.81])  # m/s^2 (gravity in -Z direction)
        for i in range(self.N):
            if self.is_boundary_constrained[i] == 0:
                rowx = self.dof_map[3*i + 0]
                rowy = self.dof_map[3*i + 1]
                rowz = self.dof_map[3*i + 2]
                if rowx != -1:
                    b[rowx] = self.mass[i] * g[0]
                    b[rowy] = self.mass[i] * g[1]
                    b[rowz] = self.mass[i] * g[2]

    # Optimized free-DOF stiffness assembly
    @ti.func
    def _add_outer_free(self, K: ti.template(), r: ti.template(), coeff: ti.f32):
        """Add outer product contribution to stiffness matrix for free DOFs"""
        k = self._cur_k[None]
        for i in ti.static(range(4)):
            ni = self.tets[k][i]
            for d1 in ti.static(range(3)):
                row = self.dof_map[3*ni + d1]
                vi = r[3*i + d1]
                if row != -1 and ti.abs(vi) >= 1e-20:
                    for j in ti.static(range(4)):
                        nj = self.tets[k][j]
                        for d2 in ti.static(range(3)):
                            col = self.dof_map[3*nj + d2]
                            vj = r[3*j + d2]
                            if col != -1 and ti.abs(vj) > 1e-20:
                                K[row, col] += coeff * vi * vj


    @ti.kernel
    def _assemble_triplets_gpu(
        self,
        rows: ti.types.ndarray(),
        cols: ti.types.ndarray(),
        vals: ti.types.ndarray(),
        cap: ti.i32,
    ):
        self._nnz_counter[None] = 0
        for k in range(self.M):
            V = self.vol[k]
            if V < 1e-12:
                V += 1e-12  # Avoid zero-volume tets
            g = ti.Vector.zero(ti.i32, 12)
            for vi in ti.static(range(4)):
                node = self.tets[k][vi]
                for d in ti.static(range(3)):
                    g[3 * vi + d] = self.dof_map[3 * node + d]
            a = self.alpha_k[k]; b = self.beta_k[k]; c = self.kappa_k[k]

            ax0 = self.r_axis[k, 0]; ax1 = self.r_axis[k, 1]; ax2 = self.r_axis[k, 2]
            sh0 = self.r_shear[k, 0]; sh1 = self.r_shear[k, 1]; sh2 = self.r_shear[k, 2]
            rv = self.r_vol[k]

            for p in ti.static(range(12)):
                gp = g[p]
                if gp != -1:
                    for q in ti.static(range(12)):
                        gq = g[q]
                        if gq != -1:
                            s_ax = ax0[p] * ax0[q] + ax1[p] * ax1[q] + ax2[p] * ax2[q]
                            s_sh = sh0[p] * sh0[q] + sh1[p] * sh1[q] + sh2[p] * sh2[q]
                            s_v = rv[p] * rv[q]
                            val = V * (4.0 * a * s_ax + 4.0 * b * s_sh + c * s_v)
                            idx = ti.atomic_add(self._nnz_counter[None], 1)
                            if idx < cap:
                                rows[idx] = ti.cast(gp, ti.i64)
                                cols[idx] = ti.cast(gq, ti.i64)
                                vals[idx] = val
    @ti.kernel
    def _assemble_K_axis_free(self, K: ti.types.sparse_matrix_builder()):
        """Assemble axial stiffness contribution"""
        for k in range(self.M):
            if self.vol[k] > 1e-12:
                self._cur_k[None] = k
                V = self.vol[k]
                coeff = 4.0 * self.alpha_k[k] * V
                for ell in ti.static(range(3)):
                    r = self.r_axis[k, ell]
                    self._add_outer_free(K, r, coeff)

    @ti.kernel
    def _assemble_K_shear_free(self, K: ti.types.sparse_matrix_builder()):
        """Assemble shear stiffness contribution"""
        for k in range(self.M):
            if self.vol[k] > 1e-12:
                self._cur_k[None] = k
                V = self.vol[k]
                coeff = 4.0 * self.beta_k[k] * V
                for s in ti.static(range(3)):
                    r = self.r_shear[k, s]
                    self._add_outer_free(K, r, coeff)

    @ti.kernel
    def _assemble_K_vol_free(self, K: ti.types.sparse_matrix_builder()):
        """Assemble volumetric stiffness contribution"""
        for k in range(self.M):
            if self.vol[k] > 1e-12:
                self._cur_k[None] = k
                V = self.vol[k]
                coeff = self.kappa_k[k] * V
                r = self.r_vol[k]
                self._add_outer_free(K, r, coeff)

    @ti.kernel
    def _scatter_solution_free(self, x_free: ti.template()):
        """Scatter solution from free DOFs back to all nodes"""
        for i in range(self.N):
            if self.is_boundary_constrained[i] == 0:
                self.solution_increment[i] = ti.Vector([
                    x_free[self.dof_map[3*i + 0]],
                    x_free[self.dof_map[3*i + 1]],
                    x_free[self.dof_map[3*i + 2]],
                ])
            else:
                self.solution_increment[i] = ti.Vector([0.0, 0.0, 0.0])

    @ti.kernel
    def _update_positions_from_solution(self):
        """Update nodal positions: x = x + delta x (for free nodes only)"""
        for i in range(self.N):
            if self.is_boundary_constrained[i] == 0:  # Free node
                self.x[i] += self.solution_increment[i]
            # Constrained nodes remain at their prescribed positions

    def solve_cone_static_equilibrium(self):
        """Solve static equilibrium for cone using SMS approach"""
        print("=== Cone Static Equilibrium (SMS) ===")
        if not hasattr(self, 'dof_map'):
            self._build_dof_map()
        self._alloc_free_buffers()
        arr_alpha = self.alpha_k.to_numpy()
        arr_beta = self.beta_k.to_numpy()
        arr_kappa = self.kappa_k.to_numpy()
        print(
            "Per-tet parameter ranges: "
            f"alpha=[{arr_alpha.min():.4e}, {arr_alpha.max():.4e}], "
            f"beta=[{arr_beta.min():.4e}, {arr_beta.max():.4e}], "
            f"kappa=[{arr_kappa.min():.4e}, {arr_kappa.max():.4e}]"
        )

        # Assemble stiffness matrix K_FF directly into Torch buffers
        n = self.b_free.shape[0]
        matrix_dim = int(self.n_free_dof)
        print(f"Matrix shape: {matrix_dim} x {matrix_dim}")

        device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
        cap = int(144 * self.M + 40 * self.N)
        rows_torch = torch.empty(cap, device=device, dtype=torch.int64)
        cols_torch = torch.empty(cap, device=device, dtype=torch.int64)
        vals_torch = torch.empty(cap, device=device, dtype=torch.float32)

        self._assemble_triplets_gpu(rows_torch, cols_torch, vals_torch, cap)
        nnz = int(self._nnz_counter.to_numpy().item())
        if nnz == 0:
            print('Assembly produced zero entries; aborting solve.')
            self.x_free.fill(0.0)
            return False

        rows_coo = rows_torch[:nnz]
        cols_coo = cols_torch[:nnz]
        vals_coo = vals_torch[:nnz]
        A_coo = torch.sparse_coo_tensor(
            torch.vstack([rows_coo, cols_coo]),
            vals_coo,
            size=(matrix_dim, matrix_dim),
            device=device,
            dtype=torch.float32,
        ).coalesce()

        # RHS: gravity loads only (boundary nodes clamped)
        self.b_free.fill(0.0)
        self._build_rhs_free(self.b_free)
        b_np = self.b_free.to_numpy().astype(np.float32)
        b_torch = torch.from_numpy(b_np).to(device)

        self.x_free.fill(0.0)

        A_dense = A_coo.to_dense()
        x_torch = torch.linalg.solve(A_dense, b_torch.unsqueeze(-1)).squeeze(-1)
        self.x_free.from_numpy(x_torch.cpu().numpy())
        print(f'Torch solve successful on {device.type.upper()} backend')
        

        # Update positions
        self._scatter_solution_free(self.x_free)
        self._update_positions_from_solution()
        return True

    def get_intersection_stats(self):
        """Get intersection statistics"""
        valid_data = self.intersection_valid.to_numpy()
        
        total_possible = self.M * 6
        total_valid = np.sum(valid_data)
        success_rate = total_valid / total_possible if total_possible > 0 else 0.0
        
        per_tet_valid = np.sum(valid_data, axis=1)
        per_tet_average = np.mean(per_tet_valid)
        
        return {
            'success_rate': success_rate,
            'per_tet_average': per_tet_average,
            'total_valid': total_valid,
            'total_possible': total_possible
        }

    def save_results(self, output_path):
        """Save SMS solution results as mesh files"""
        # Save mesh files instead of NPZ data files

        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        # Get final deformed positions
        final_positions = self.x.to_numpy()
        initial_positions = self.initial_positions.to_numpy()
        solution_increment = self.solution_increment.to_numpy()
        fem_displacement = self.displacement_field.to_numpy()

        # Create mesh data for output
        cells = [("tetra", self.mesh_connectivity)]
        cell_data = {"labels": [self.labels_np]} if self.labels_np is not None else {}

        def build_xdmf_path(suffix: str) -> Path:
            return output_path.parent / f"{output_path.name}_{suffix}.xdmf"

        # Save initial mesh (reference configuration)
        initial_mesh = meshio.Mesh(points=initial_positions, cells=cells, cell_data=cell_data)
        initial_path = build_xdmf_path("initial")
        meshio.write(str(initial_path), initial_mesh, data_format="XML")
        print(f"Initial mesh saved to {initial_path}")

        # Save FEM reference solution
        fem_final_positions = initial_positions + fem_displacement
        fem_mesh = meshio.Mesh(
            points=fem_final_positions,
            cells=cells,
            cell_data=cell_data,
        )
        fem_path = build_xdmf_path("fem_reference")
        meshio.write(str(fem_path), fem_mesh, data_format="XML")
        print(f"FEM reference mesh saved to {fem_path}")

        # Save SMS solution
        sms_mesh = meshio.Mesh(
            points=final_positions,
            cells=cells,
            cell_data=cell_data,
        )
        sms_path = build_xdmf_path("sms_solution")
        meshio.write(str(sms_path), sms_mesh, data_format="XML")
        print(f"SMS solution mesh saved to {sms_path}")

        # Save displacement comparison mesh with point data
        comparison_mesh = meshio.Mesh(
            points=final_positions,
            cells=cells,
            point_data={
                "SMS_displacement": solution_increment,
                "FEM_displacement": fem_displacement,
                "displacement_error": solution_increment - fem_displacement,
                "displacement_error_magnitude": np.linalg.norm(
                    solution_increment - fem_displacement, axis=1
                ),
            },
            cell_data=cell_data,
        )
        comparison_path = build_xdmf_path("comparison")
        meshio.write(str(comparison_path), comparison_mesh, data_format="XML")
        print(f"Comparison mesh with displacement data saved to {comparison_path}")

        # Also save summary data as NPZ for analysis
        summary_data = {
            'final_positions': final_positions,
            'initial_positions': initial_positions,
            'solution_increment': solution_increment,
            'boundary_nodes': self.boundary_nodes.to_numpy(),
            'is_constrained': self.is_boundary_constrained.to_numpy(),
            'fem_displacement': fem_displacement,
            'mesh_connectivity': self.mesh_connectivity,
            'alpha_k': self.alpha_k.to_numpy(),
            'beta_k': self.beta_k.to_numpy(),
            'kappa_k': self.kappa_k.to_numpy(),
            'labels': self.labels_np,
            'mesh_info': {
                'n_nodes': self.N,
                'n_tetrahedra': self.M,
                'n_free_dof': self.n_free_dof if hasattr(self, 'n_free_dof') else 0
            }
        }
        if self.nu_value is not None:
            summary_data['nu'] = self.nu_value
        summary_path = output_path.parent / f"{output_path.name}_summary.npz"
        np.savez(str(summary_path), **summary_data)
        print(f"Summary data saved to {summary_path}")

        return {
            'initial_mesh': str(initial_path),
            'fem_reference': str(fem_path),
            'sms_solution': str(sms_path),
            'comparison': str(comparison_path),
            'summary': str(summary_path)
        }

    def summary(self):
        """Print cone simulation summary"""
        total_mass = self.mass.to_numpy().sum()
        print(f"Cone: {self.N} nodes, {self.M} tets, total mass={total_mass:.6f} kg")
        
        stats = self.get_intersection_stats()
        print(f"Intersection success rate: {stats['success_rate']:.2%}")
        print(f"Average intersections per tet: {stats['per_tet_average']:.1f}/6")

    def compare_with_fem(self):
        """Compare SMS solution with FEM reference"""
        # Added quantitative comparison between SMS and FEM solutions
        sms_displacement = self.solution_increment.to_numpy()
        fem_displacement = self.displacement_field.to_numpy()
        
        # Only compare free nodes (non-constrained)
        is_free = self.is_boundary_constrained.to_numpy() == 0
        
        sms_free = sms_displacement[is_free]
        fem_free = fem_displacement[is_free]
        
        # Compute error metrics
        abs_error = np.linalg.norm(sms_free - fem_free, axis=1)
        rel_error = abs_error / (np.linalg.norm(fem_free, axis=1) + 1e-10)
        
        print(f"\n=== SMS vs FEM Comparison ===")
        print(f"Free nodes: {np.sum(is_free)}/{self.N}")
        print(f"Max absolute error: {abs_error.max():.6e} m")
        print(f"Mean absolute error: {abs_error.mean():.6e} m")
        print(f"RMS absolute error: {np.sqrt(np.mean(abs_error**2)):.6e} m")
        print(f"Max relative error: {rel_error.max():.6f}")
        print(f"Mean relative error: {rel_error.mean():.6f}")
        
        return {
            'max_abs_error': abs_error.max(),
            'mean_abs_error': abs_error.mean(),
            'rms_abs_error': np.sqrt(np.mean(abs_error**2)),
            'max_rel_error': rel_error.max(),
            'mean_rel_error': rel_error.mean()
        }


def run_cone_verification():
    """Run complete cone verification"""
    base_dir = Path(__file__).resolve().parent
    xdmf_dir = base_dir / "xdmf_visualization"
    preprocessed_data_path = base_dir / "cone_verification_deformation.npz"
    output_path = xdmf_dir / "cone_sms_solution"

    if not preprocessed_data_path.exists():
        print(f"Error: Preprocessed data not found at {preprocessed_data_path}")
        print("Please run hetero_cone_deformation_processor.py first")
        return None

    print("=== Loading Preprocessed Cone Data ===")
    sim = ConeStaticEquilibrium(str(preprocessed_data_path))

    print("=== Applying Cone Boundary Conditions ===")
    sim.apply_cone_boundary_conditions()

    sim.summary()

    print("\n=== Solving Cone Static Equilibrium ===")
    success = sim.solve_cone_static_equilibrium()

    if success:
        print("SMS solution successful!")
        comparison = sim.compare_with_fem()
        mesh_files = sim.save_results(output_path)

        print("\n=== Output Files ===")
        for file_type, path in mesh_files.items():
            print(f"  {file_type}: {path}")

        return comparison

    print("SMS solution failed!")
    return None


if __name__ == "__main__":
    comparison = run_cone_verification()
    
    if comparison:
        print("\n=== Verification Complete ===")
        print("The SMS approach achieved:")
        print(f"  Max absolute error: {comparison['max_abs_error']:.6e} m")
        print(f"  Mean relative error: {comparison['mean_rel_error']:.4%}")
        print("\nMesh files saved to xdmf_visualization/:")
        print("  - Initial configuration: cone_sms_solution_initial.xdmf")
        print("  - FEM reference solution: cone_sms_solution_fem_reference.xdmf") 
        print("  - SMS solution: cone_sms_solution_sms_solution.xdmf")
        print("  - Comparison with error data: cone_sms_solution_comparison.xdmf")
